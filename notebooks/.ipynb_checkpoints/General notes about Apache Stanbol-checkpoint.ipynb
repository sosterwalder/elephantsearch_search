{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Entities\n",
      "\n",
      "## Content item\n",
      "* Object which represents the content to be enhanced by Apache Stanbol\n",
      "\n",
      "![Foo](/files/images/contentitemoverview.png)\n",
      "\n",
      "### Content parts\n",
      "* Are used to represent the original content as well as transformations of the orig. content\n",
      "\n",
      "#### Analysed text\n",
      "* Used as content part\n",
      "* Describes\n",
      " * Structure of the text, such as text-sections, sentencens, chunks and tokens\n",
      " * Annotations for the detected text\n",
      "\n",
      "\n",
      "# Enhancer\n",
      "* Allows to extract features from passed content\n",
      "* Uses enhancement engines based on the called enhancement chain\n",
      "\n",
      "## Enhancement engines\n",
      "\n",
      "### Preprocessing\n",
      "* Content type detection\n",
      "* Text extraction\n",
      "\n",
      "### Natural Language Processing (NLP)\n",
      "\n",
      "* Language detection\n",
      " * Adds language annotation (as defined by STANBOL-613) to the metadata of a content-item\n",
      "\n",
      "* Sentence detection\n",
      " * Adds sentences to the analyed text content part\n",
      "\n",
      "* Tokenizer engines\n",
      " * Adds tokens to the analyzed text content part\n",
      "\n",
      "* Part of speech tagging\n",
      " * Zuordnung von W\u00f6rtern und Satzzeichen zu Wortarten (Verb, Substantiv etc.)\n",
      "\n",
      "* Chunk / prhase detection\n",
      " * Adds detected chunks to analyzed text content part\n",
      " * Annotate added chunks with the type of the detected phrase\n",
      "\n",
      "* Named entity recognition (NER)\n",
      " * Writes detected named entities as annotations to the metadata of the content-item\n",
      " ![Alt text](files/images/es_textannotation.png)\n",
      " \n",
      "* Morphological analysis\n",
      "  * Performes lemmatization (lexikographische Reduktion der Flexionsformen eines Wortes auf eine Grundform)\n",
      "\n",
      "* General NLP processing engines\n",
      "\n",
      "### Linking / suggestions\n",
      "\n",
      "* Suggestion of entities for features present in the parsed content\n",
      "* Provides\n",
      " * Type\n",
      " * Description\n",
      " * Spatial and/or temporal content\n",
      " * Links to other entities\n",
      " \n",
      "* Named Entity\n",
      " * Suggests links to several linked data sources\n",
      "\n",
      "* Entityhub\n",
      " * Suggests links to entities managed by entity hub, referenced sites or managed sites\n",
      "\n",
      "* FST (Finite State Transfer)\n",
      " * Links entities indexed in a Solr database\n",
      " \n",
      "* Entity co-mention\n",
      " * Detects co-mentions of a deteceted entity at a later position\n",
      " \n",
      "* DBPedia spotlight annotation engine\n",
      " * Includes NLP, Entity Linking and Disambiguation of Entities using DBpedia as knowledge base\n",
      " \n",
      "* Geonames\n",
      " * Suggests links to geonames.org\n",
      " \n",
      "* OpenCalais\n",
      " * Integerates services from Open Calais\n",
      " * Provides both NER and entity linking \n",
      " \n",
      "* Zemanta\n",
      " * Integrates services from Zemanta\n",
      " * Provides both NER and entity linking \n",
      " \n",
      "* Sentiment analyses\n",
      " * Engines that perform word/chunk level sentiment classifications on the analyed text\n",
      " \n",
      "* Disambiguation\n",
      " * Disambiguation (Aufl\u00f6sen von Mehrdeutigkeiten) entities based on contextual information\n",
      " \n",
      "### Postprocessing / other\n",
      "\n",
      "* Not yet covered :)\n",
      "\n",
      "## Enhancement structure\n",
      "\n",
      "* Represents the state of enhancement based upon the content item and the content parts\n",
      "* Gets constantly updated during the enhancement process\n",
      "\n",
      "### General information\n",
      "\n",
      "#### Used namespaces\n",
      "\n",
      "* fise\n",
      " * This is the main namespace of the currently used Enhancement Structure. All custom concepts and properties are defined using this namespace.\n",
      "\n",
      "* enhancer\n",
      " * This is the main namespace of the Stanbol Enhancer defining concepts such as ContentItem, EnhancementEngine, EnhancementChain \u2026\n",
      "\n",
      "* entityhub\n",
      " * This is the main namespace of the Stanbol Entityhub component. \n",
      "\n",
      "* dc \n",
      " * The Dublin Core terms standard is also heavily used by the Stanbol Enhancement Structure. Especially to encode metada data, but also to encode relations between extracted information \n",
      "\n",
      "* dppedia-ont\n",
      " * Concepts of this Ontology are used to describe the types of \"Named Entities\" detected in parsed content.\n",
      "\n",
      "* skos\n",
      " * The SKOS standard is preferable used to describe entries of Thesauri or more generally any type of controlled vocabularies.\n",
      "\n",
      "* rdf\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}